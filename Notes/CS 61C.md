[**CS 61C** **Spring 2019** ](https://inst.eecs.berkeley.edu/~cs61c/sp19/)	 
[Resources ](https://inst.eecs.berkeley.edu/~cs61c/sp21/resources/)


# [Project 4: Performance Programming](https://inst.eecs.berkeley.edu/~cs61c/sp19/projects/proj4/)

## Στόχοι
- χρησιμοποιήστε τις τεχνικές προγραμματισμού επιδόσεων που μάθατε στην τάξη για να επιταχύνετε τις εργασίες αναγνώρισης εικόνων.
- να εφαρμοστεί ο νόμος του Amdahl για να διαπιστωθεί πού πρέπει να επικεντρωθούν οι περισσότερες προσπάθειες.
- να επικεντρώνεστε πρώτα στις μεγάλες βελτιώσεις της ταχύτητας πριν επιχειρήσετε μικρο-βελτιστοποιήσεις.

## Getting Started
Πήραμε τον κώδικα από το Github: https://github.com/61c-teach/sp19-proj4-starter. 

## Θεωρητικό Υπόβαθρο 
Εφαρμογή τεχνικών βελτιστοποίησης απόδοσης στο πρόβλημα της ταξινόμησης εικόνων με χρήση Συνελικτικών Νευρωνικών Δικτύων 

### Πώς ένας υπολογιστής αναγνωρίζει εικόνες;
Η ταξινόμηση εικόνων περιγράφει ένα πρόβλημα στο οποίο σε ένα υπολογιστή δίνεται μία εικόνα και πρέπει να καταλάβει τι απεικονίζει (από ένα σύνολο πιθανών κατηγοριών).

Σήμερα, τα Συνελικτικά Νευρωνικά Δίκτυα (CNNs) αποτελούν  μια πολύ καλή  προσέγγιση αυτού το προβλήματος. Γενικά, τα νευρωνικά δίκτυα υποθέτουν πως υπάρχει κάποια συνάρτηση από την είσοδο (π.χ. εικόνες) σε μία έξοδο (π.χ. ένα σύνολο κατηγοριών εικόνων). Ενώ οι κλασσικοί αλγόριθμοι προσπαθούν να κωδικοποιήσουν  κάποια πληροφορία του πραγματικού κόσμου στη συνάρτηση τους, τα CNN μαθαίνουν την συνάρτηση δυναμικά  από ένα σύνολο ταξινομημένων εικόνων (labelled images)—αυτή η διαδικασία ονομάζετε εκπαίδευση. Μόλις καταλήξει σε μια σταθερή συνάρτηση (δηλαδή σε μια προσέγγιση αυτής), μπορεί να εφαρμόσει τη συνάρτηση σε εικόνες που δεν έχει ξαναδεί.

### Τι μπορεί να κάνει ένα νευρωνικό δίκτυο; 

Ένα νευρωνικό δίκτυο αποτελείται από πολλαπλά επίπεδα.  Κάθε επίπεδο λαμβάνει έναν πολυδιάστατο πίνακα αριθμών ως είσοδο και παράγει έναν άλλο πολυδιάστατο πίνακα αριθμών ως έξοδο (ο οποίος στη συνέχεια γίνεται η είσοδος του επόμενου επιπέδου). Κατά την ταξινόμηση εικόνων, η είσοδος του πρώτου επιπέδου είναι η εικόνα εισόδου  (π.χ. 32x32x3 αριθμοί για εικόνες 32x32 pixel με 3 κανάλια χρώματος), ενώ η έξοδος του τελευταίου επιπέδου αποτελείται  ένα σύνολο πιθανοτήτων των διαφόρων κατηγοριών (π.χ. 1x1x10 αριθμοί αν υπάρχουν 10 κατηγορίες). 

![CNN-network](network.png)

Κάθε επίπεδο έχει ένα σύνολο από βάρη που σχετίζονται με αυτό — αυτά τα βάρη είναι που “μαθαίνει” το νευρωνικό όταν του δοθούν δεδομένα εκπαίδευσης. Ανάλογα με το επίπεδο, τα βάρη έχουν διαφορετικές ερμηνείες, αλλά δεν είναι αντικείμενο μελέτης της συγκεκριμένης διπλωματικής, φτάνει να γνωρίζουμε ότι κάθε επίπεδο λαμβάνει μία είσοδο, εκτελεί κάποια διεργασία σε αυτή, που εξαρτάται από τα βάρη και παράγει μια έξοδο. Αυτό το βήμα ονομάζεται **εμπρόσθια διάδοση**: παίρνουμε μία είσοδο και την προωθούμε στο δίκτυο, παράγοντας το επιθυμητό αποτέλεσμα ως έξοδο. Η εμπρόσθια διάδοση είναι το μόνο που χρειάζεται για την ταξινόμηση εικόνων σε ένα ήδη εκπαιδευμένο CNN. 

Στην πράξη, ένα νευρωνικό δίκτυο αποτελεί μια πολύ απλή μηχανή αναγνώρισης προτύπων (με [εξαιρετικά περιορισμένη χωρητικότητα](http://tfmeter.icsi.berkeley.edu/)), αλλά μπορεί να είναι αρκετά παράξενο αυτό που καταλήγει να αναγνωρίσει. Για παράδειγμα, κάποιος μπορεί να εκπαιδεύσει ένα νευρωνικό δίκτυο να αναγνωρίζει τη διαφορά μεταξύ “σκύλων” και “λύκων”, και να δουλέψει καλά κοιτώντας το χιόνι και το δάσος στο φόντο των φωτογραφιών με τους λύκους.

## Σκοπός της Διπλωματικής

Γίνεται έρευνα σχετικά με τις διαφορετικές αρχιτεκτονικές νευρωνικών δικτύων και τις μεθόδους εκπαίδευσης. Ωστόσο, μια άλλη κρίσιμη πτυχή των νευρωνικών δικτύων είναι, δεδομένου ενός εκπαιδευμένου δικτύου, η γρήγορη και ακριβής ταξινόμηση εικόνων. Στον κώδικα που διαθέτουμε, δίνετε ένα εκπαιδευμένο νευρωνικό δίκτυο που ταξινομεί εικόνες 32x32 RGB σε 10 κατηγορίες. Οι εικόνες ανήκουν στο dataset [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). 

Μας δίνετε ο αλγόριθμος εμπρόσθιας διάδοσης του νευρωνικού δικτύου και τα τελικά βάρη του δικτύου. Σκοπός είναι η βελτίωση της ταχύτητας της εμπρόσθιας διάδοσης ώστε να γίνει ταξινόμηση με πιο γρήγορο ρυθμό. 

## Κατανόηση του Κώδικα

### Δομή φακέλου

Ο φάκελος περιλαμβάνει τα παρακάτω αρχεία:

```
Makefile
layers.h
snapshot/
layers_baseline.c
test/
benchmark.c
network.c
volume.c
network.h
volume.h
huge_test.sh
network_baseline.c
layers.c
run_test.sh
```
Τα μόνα αρχεία που επεμβαίνουμε είναι:

- **`layers.c`**
- **`network.c`**
- **`volume.c`**



Τα αρχεία `layers_baseline.c`, `network_baseline.c`, και `volume_baseline.c` περιλαμβάνουν την σειριακή έκδοση του κώδικα σαν σημείο αναφοράς για μέτρηση της επιτάχυνσης.

### Επισκόπηση Κώδικα 
Στον κώδικα χρησιμοποιούνται διάφοροι τύποι δεδομένων. Με τον όρο τύποι δεδομένων, εννοούμε τις δομές που με την [`typedef`](https://en.wikipedia.org/wiki/Typedef)έχουν μετονομαστεί ώστε να έχουν νόημα. Επίσης στα header files υπάρχουν περιγραφές για το τι κάνει κάθε συνάρτηση.

Πρώτος τύπος δεδομένων `volume_t`, περιλαμβάνει έναν τρισδιάστατο πίνακα (ή όγκο) μεταβλητών double. Χρησιμοποιείται για την αναπαράσταση των αποτελεσμάτων κάθε επιπέδου, καθώς και για τα βάρη κάποιων επιπέδων.

Στη συνέχεια, έχουμε τα διαφορετικά είδη επιπέδων:  `conv`, `relu`, `pool`, `fc`, και `softmax`.  Για το καθένα από αυτά υπάρχει:

- Μία δομή δεδομένων που περιέχει την περιγραφή των παραμέτρων του επιπέδου. Κάθε επίπεδο έχει συγκεκριμένο αριθμό παραμέτρων που δεν αλλάζει κατά την διάρκεια της εκτέλεσης του προγράμματος. Για παράδειγμα,το μέγεθος των όγκων της εισόδου και εξόδου ενός επιπέδου δηλώνεται στον ορισμό του CNN.
- Μία συνάρτηση `*_forward`  οποία εκτελεί την κύρια λειτουργία του επιπέδου. Αυτές οι συναρτήσεις αυτές παίρνουν τη δομή δεδομένων του επιπέδου , και έναν πίνακα pointers των όγκων των εισόδων και των εξόδων. Επιπλέον οι μεταβλητές `start` και `end` iδείκτες σε αυτό τον πίνακα. Αυτό επιτρέπει σε κάθε επίπεδο να επεξεργάζεται μια ομάδα εισόδων , το οποίο θα χρησιμεύσει στη βελτιστοποίηση. Για παράδειγμα, μπορεί να έχουμε έναν πίνακα με pointers σε μια είσοδο και να ορίσουμε  `start = 5` και `end = 9` για την επεξεργασία των εισόδων `5,6,7,8,9` μαζί και επιστρέφουν το αποτέλεσμα στους αντίστοιχους πίνακες εξόδων.
- Δύο συναρτήσεις,την `make_*` και `*_load`.  Η πρώτη παράγει ένα επίπεδο και με συγκεκριμένο σύνολο παραμέτρων, και η δεύτερη φορτώνει τα βάρη του επιπέδου από αρχείο στον υπολογιστή.

Τελευταία σημαντική δομή δεδομένων είναι η  `network_t`, η οποία περιέχει όλες τις πληροφορίες που περιγράφουν το CNN. Αυτό περιλαμβάνει όλα τα επιπεδα, και μία παράμετρο που αφορά στους διάφορους ενδιάμεσους όγκους(Volumes). Να σημειωθέι πως αυτοί οι όγκοι (Volumes) δεν χρησιμοποιούνται ουσιαστικά για την αποθήκευση δεδομένων (αυτό γίνεται με τα batches που περιγράφονται παρακάτω). Χρησιμοποιούνται για να υπάρχουν διαθέσιμες οι διαστάσεις του κάθε όγκου.

Όλα τα ενδιάμεσα δεδομένα αναπαρίστανται ως batches. Περιλαμβάνουν τα ενδιάμεσα δεδομένα που σχετίζονται με ένα σύνολο εικόνων εισόδου. Το `batch_t` είναι συντομογραφία του `volume_t***`, πρόκειται δηλαδή για δισδιάστατους πίνακες δεικτών σε Volumes. Η πρώτη διάσταση δηλώνει το επιπέδου που ανήκει το Volume (π.χ., V0, V1, κλπ. στο σχήμα παραπάνω) και η δεύτερη διάσταση δηλώνει την είσοδο. Στο αρχικό πρόγραμμα τα batches έχουν μέγεθος 1 (π.χ., επεξεργαζόμαστε ένα παράδειγμα κάθε φορά), για παραλληλοποίηση θα χρειαστούν μεγαλύτερα batches, τα οποία  κάνουμε allocate στη μνήμη με την συνάρτηση `make_batch` και απελευθερώνουμε από τη μνήμη με την `free_batch`.

Τέλος, η συνάρτηση `net_forward` δέχεται ένα batch (καθώς και δείκτες `start/end`) και εφαρμόζει το CNN για κάθε είσοδο από την αρχή μέχρι το τέλος καλώντας τις συναρτήσεις forward για κάθε επίπεδο. Αυτή η συνάρτηση χρησιμοποιείται από την `net_classify`. Παίρνει ένα σύνολο εικόνων, βάζει κάθε μία από αυτές στο volume V0 ενός στοιχείου του batch, και στη συνέχεια τρέχει το δίκτυο σε αυτά.  Αποθηκεύουμε τα likelihoods (δηλαδή τις τιμές στο τελευταίο επίπεδο του δικτύο) σε έναν 2D πίνακα τύπου double ώστε να δούμε που θα ταξινομούσε το δίκτυο την εικόνα.

##  Profiling και νόμος του Amdahl

Όταν βελτιστοποιούμε κώδικα, πρώτα αποφασίζουμε σε ποια σημεία το πρόγραμμά μας ξοδεύει τον περισσότερο χρόνο του. Για παράδειγμα, κάνοντας πιο γρήγορο ένα κομμάτι κώδικα που καταλαμβάνει μόνο το 5% του συνολικού χρόνου εκτέλεσης, θα έχει σαν αποτέλεσμα το πολύ 5% επιτάχυνση και μάλλον δεν αξίζει τον κόπο.

Ο νόμος του Amdahl, αποτελεί ένα πολύ καλό τρόπο για την εκτίμηση της αναμενόμενης βελτίωσης. Για την εφαρμογή του νόμου του Amdahl, πρώτα πρέπει να βρούμε τι ποσοστό του χρόνου ξοδεύεται στα διάφορα μέρη του προγράμματος

### Χρήση του Gprof
Το Gprof είναι ένα εργαλείο για profiling σε κώδικα, το οποίο θα χρησιμοποιήσουμε 
ώστε να δούμε ποιές συναρτήσεις επωφελούνται από τις βελτιστοποιήσεις που κάναμε.
Τρέχουμε το Gprof αφού κάνουμε compile το πρόγραμμα με το flag "-pg":

```
make clean
make baseline CFLAGS="-Wall -Wno-unused-result -march=haswell -std=c99 -fopenmp -pg -O0"
```
Στη συνέχεια τρέχουμε τον κώδικα:

```
./benchmark_baseline benchmark
```
Τέλος, βλέπουμε τα αποτελέσματα του Gprof.

```
gprof benchmark_baseline | less
```

Από τα αποτελέσματα που παίρνουμε κοιτάμε το Flat profile :
```
 %   cumulative   self              self     total
time   seconds   seconds    calls   s/call   s/call  name
```
οι στήλες που μας ενδιαφέρουν είναι:

- `% time`: Ο χρόνος που το πρόγραμμα ξοδεύει σε μια συνάρτηση 
- `calls`: Πόσες φορές έχει γίνει κλήση μιας συνάρτησης 
- `name`: Το όνομα της συνάρτησης.
- 
### Ερμηνεία των αποτελεσμάτων
Πρώτα, κρατάμε τις 10 πρώτες συναρτήσεις ως προς το τι ποσοστό του χρόνου το πρόγραμμα μας ξοδεύει σε αυτές. Ο νόμος του Amdahl μας λέει ποιες συναρτήσεις θα επωφεληθούν περισσότερο από τις βελτιστοποιήσεις, γι' αυτό το λόγο προτείνουμε να εστιάσετε σε αυτές τις 10 πρώτες συναρτήσεις. 

Να σημειωθεί ότι ορισμένες σχετικά απλές συναρτήσεις μπορεί να βρίσκονται στην πρώτη δεκάδα επειδή καλούνται πολλές φορές (εκατομμύρια για ορισμένες σε σύγκριση με χιλιάδες για άλλες). Αν και η βελτιστοποίησή τους θα επιτάχυνε σίγουρα το πρόγραμμά μας, οι συναρτήσεις αυτές μπορεί να είναι τόσο μικρές που είναι δύσκολο να βελτιστοποιηθούν. Προσοχή! 

### Ενδιάμεσο Profiling

Εάν θέλετε να κάνετε profile στον βελτιστοποιημένο κώδικα για να δείτε που χρειάζεται να επικεντρώσετε την προσοχή σας, τρέξτε τις παρακάτω εντολές: 
```
make clean
make CFLAGS="-Wall -Wno-unused-result -march=haswell -std=c99 -fopenmp -pg -O0"
./benchmark benchmark
gprof benchmark | less
```
Οι χρόνοι δεν θα είναι ακριβείς καθώς ο gprof επιβραδύνει την εκτέλεση, αλλά δίνει μια γενική ιδέα για το τι ποσοστό του χρόνου χρησιμοποιεί μια συνάρτηση.

## Step 3: Unrolling και άλλα Optimizations
Προηγουμένως βρήκαμε συναρτήσεις που αξίζει να βελτιστοποιηθούν. Πρώτα προσπαθήστε να βελτιστοποιήσετε την ταχύτητα του κώδικα εφαρμόζοντας συμβατικά optimization στον κώδικα. (π.χ. χωρίς SIMD ή πολλαπλά threads).  
Μερικά hints για να ξεκινήσεται:
- Μερικές φορές μπορεί να γίνει αντικατάσταση μιας συνάρτησης με πολλές ειδικές συναρτήσεις που κάνουν το ίδιο πράγμα αλλά είναι βελτιστοποιημένες για συγκεκριμένες τιμές εισόδου. Στη συνέχεια καλέστε αυτές τις ειδικές συναρτήσεις από την αρχική συνάρτηση. 
- Υπάρχουν σημεία στο πρόγραμμα όπου μια μεταβλητή έχει πάντα την ίδια τιμή αλλά φορτώνεται στην μνήμη κάθε φορά; 
- Υπάρχουν σημεία που θα μπορούσε να γίνει χειροκίνητα loop unrolliing? 
- Μπορείτε να ταξινομήσετε πολλαπλά δείγματα ταυτόχρονα αντί για ταξινόμηση το ένα μετά το άλλο; 
- Υπάρχει καλύτερος τρόπος διάταξης των διαφορετικών loop? 

Οι παραπάνω τεχνικές σχετίζονται με γενικούς κανόνες βελτιστοποιήσεων. Δεν χρειάζεται απαραίτητα να γίνουν όλα για να επιτευχθεί μια καλή ταχύτητα. 

Αφού έχετε βελτιώσει την ταχύτητα χρησιμοποιώντας αυτά τα optimizations, μπορείτε να ξεκινήσετε να εφαρμόζεται vectorization και παραλληλία για να κάνετε το πρόγραμμα ακόμη πιο γρήγορο. Πειραματιστείτε με διαφορετικές προσεγγίσεις για να δείτε ποια δίνει την καλύτερη απόδοση. 

## Step 4: Εντολές SIMD
Εφαρμογή εντολών SIMD που βελτιώνουν την απόδοση. Οι επεξεργαστές που υποστηρίζουν την επέκταση AVX της Intel, επιτρέπουν την εκτέλεση πράξεων SIMD σε τιμές 256 bit (όχι μόνο 128 bit). Να χρησιμοποιηθεί αυτή η επέκταση για παράλληλη εκτέλεση πραξεων καθώς όλα οι αριθμοί floating point είναι double, 64 bit σε μέγεθος. 

Υπενθυμίζεται, μπορείτε να χρησιμοποιήσετε [Intel Intrinsics Guide](https://software.intel.com/sites/landingpage/IntrinsicsGuide/)σαν reference για τις σχετικές εντολές. 
Πρέπει να χρησιμοποιήσετε τον τύπο `__m256d` για αποθήκευση 4 double σε έναν [YMM register](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions),  και μετά να χρησιμοποιήσετε το `_mm256_*` intrinsics για πράξεις. 

## Step 5: OpenMP
Τέλος, χρησιμοποιείστε την OpenMP για παρααλληλοποίηση των υπολογισμών. Να σημειωθεί πως ο πιο εύκολος τρόπος παραλληλοποίης ενός μεγάλου αριθμού εικόνων θα είναι η ταξινόμηση batch εικόνων παράλληλα (καθώς αυτά τα batches είναι ανεξάρτητα). Σιγουρευτείτε ότι κανένα από τα διαφορετικά threads δεν θα κάνει overwrite στα δεδομένα του άλλου.  Η απλή προσθήκη του #pragma omp parallel μπορεί να προκαλέσει σφάλματα.  

Με 4 cores που έχουν 2 hyperthreads το καθένα περιμένουμε ένα speed-up 4-8x ( τα hyperthreads σημαίνει ότι δύο διαφορετικά προγράμματα μπορούν να εκτελεστούν στο ίδιο physical core την ίδια στιγμή. γι αυτό το λόγο αυτά ανταγωνίζονται για processor resources, και σαν αποτέλεσμα δεν παίρνεις την ίδια απόδοση όπως αν έτρεχαν σε δύο διαφορετικά cores). 

## Έλεγχος Ορθότητας  

Υπάρχουν τρείς τρόποι για τον έλεγχο του κώδικα. Πριν από κάθε έλεγχο να γίνεται compile  με τις εξής εντολές: 
```
make clean && make
```

### Regular Benchmark
Τρέχοντας τον κώδικα με την εντολή 
```
./benchmark benchmark
```
βλέπουμε πόσο γρήγορα μπορεί να τρέξει ο κώδικας για ένα υποσύνολο 1200 εικόνων. Αν δεν προσθέσουμε κάποιο argument παίρνουμε το παρακάτω αποτέλεσμα: 
```
RUNNING BENCHMARK ON 1200 PICTURES...
Making network...
Loading batches...
Loading input batch 0...
Running classification...
78.250000% accuracy
_________ microseconds
```

ο αριθμός που παίρνουμε αντιστοιχεί στο πόσο κάνει το δίκτυο για να ταξινομήσει τις εικόνες. Μετράμε μόνο τον ταχύτητα της ταξινόμησης. Δεν περιλαμβάνεται σε αυτόν ο χρόνος για τη φόρτωση των εικόνων στη μνήμη ή άλλα setup/teardown tasks. 

H ακρίβεια υπολογίζεται για να τσεκάρουμε ευκολά ότι η υλοποίηση μας είναι σωστή. Εάν η ακρίβεια διαφέρει (π.χ. δεν είναι **`78.25%`**), αυτό σημαίνει πως υπάρχει κάποιο πρόβλημα με την υλοποίηση. για περισσότερη λεπτομέρεια ως προς το τι πήγε λάθος, τρέχουμε τα scripts `run_test.sh` και `huge_test.sh` (περιγράφονται παρακάτω) ώστε να εντοπίσουμε πιο εύκολα σε ποιο layer συμβαίνει το σφάλμα. 

αν το τεστ παίρνει πολύ ώρα, τρέξτε το benchmark με έναν μικρότερο αριθμό εικόνων με την παρακάτω εντολή: 
```
./benchmark benchmark n
```
Όπου `n` είναι ένας ακέραιος αριθμός που αντιπροσωπεύει τον αριθμό εικόνων που θέλουμε να τρέξουμε το benchmark. Σε αυτή την περίπτωση το αποτέλεσμα μπορεί να μην είναι ακριβώς `78.25%`, καθώς κάνουμε τεστ σε διαφορετικό υποσύνολο εικόνων. Για να επιβεβαιώσουμε ότι η υλοποίηση είναι σωστή μπορούμε να τρέξουμε την παρακάτω εντολή: 
```
make baseline
./benchmark_baseline benchmark n
```
όπου το `n` θα είναι ίδιο με παραπάνω, και στη συνέχεια συγκρίνουμε τις ακρίβειες που τυπώνονται από την εκτέλεση της κάθε εντολής. Αν υπάρχει διαφορά, τότε κάποιο σφάλμα υπάρχει στην υλοποίηση. Παρόλα αυτά, ακόμη κι αν είναι ίδια οι παρακάτω δύο μέθοδοι επιβεβαιώνουν την ορθότητα της υλοποίησης. 

### `run_test.sh`
αυτό το script τρέχει το νευρωνικό δίκτυο σε 20 εικόνες και τυπώνει τις ακριβείς τιμές για κάθε επίπεδο. Τις συγκρίνει με τις reference τιμές που έχουν παραχθεί από το αρχικό unoptimized κώδικα και ελέγχει αν οι τιμές είναι ίδιες (ως ένα λογικό βαθμό σφάλματός λαμβάνοντας υπόψιν τα floating point errors). 

επίσης, αυξάνει τον αριθμό του υποσυνόλου των εικόνων ώστε να βρεθούν κι άλλα σφάλματα παραλληλισμού. για αυτά τα παράλληλα τεστ, απλά συγκρίνονται οι έξοδοι του τελευταίου επιπέδου του νευρωνικού δικτύου με αυτό του unoptimized κώδικα. 

Αυτό είναι πιο fine-grained test από το `./benchmark benchmark` καθώς επιβεβαιώνει ότι το νευρωνικό εκτελεί εικονικά τους ίδιους υπολογισμούς με τον αρχικό κώδικα. Συνίσταται μετά από κάθε μεγάλη αλλαγή στον κώδικά ώστε να επιβεβαιώνετε πως δεν έχει επίπτωση στην ορθότητα.

### huge_test.sh
Αυτό το script τρέχει σχεδόν τα ίδια με το `run_test.sh`, με εξαίρεση ότι τρέχει κώδικά σε δύο επιπλέον πολύ μεγάλα υποσύνολα εικόνων. Δεν χρειάζεται να το τρέχετε συχνά (παίρνει πολύ χρόνο). 

## Debugging
Για debugging χρησιμοποιούμε το CGDB και Valgrind. Για χρήση του CGDB, πρόσθέτουμε το flag “-g” στο CFLAGS με την παρακάτω εντολή: 
```
make CFLAGS="-Wall -Wno-unused-result -march=haswell -std=c99 -fopenmp -g -O0"
cgdb ./benchmark
```
Στο cgdb ορίζουμε breakpoints και εκτελούμε 
```
run benchmark
```
Σε περίπτωση segfault, το Valgrind βοηθάει στο να βρούμε που είναι το σφάλμα. Μια απλή εντολή για αυτό είναι: 
```
valgrind --leak-check=full --show-leak-kinds=all ./benchmark benchmark
```
Note that executing your program in valgrind will take much longer than usual.

### Μέτρηση του speedup 

Για τη μέτρηση της επιτάχυνσης του κώδικα τρέχουμε την εντολή
```
make compare
```
πρώτα εκτελείται ο βελτιστοποιημένος κώδικάς κα δεύτερος ο σειριακός κώδικας. 


## References
- [Learning Multiple Layers of Features from Tiny Images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf), Alex Krizhevsky, 2009.
- Andrej Karpathy’s ConvNetJS implementation. <https://cs.stanford.edu/people/karpathy/convnetjs/>
- Gerald Friedland, An Explainable Neural Network. [http://tfmeter.icsi.berkeley.edu](http://tfmeter.icsi.berkeley.edu/)

